
\chapter{ОСНОВНЫЕ РЕЗУЛЬТАТЫ ТЕОРИИ ОПТИМАЛЬНОГО УПРАВЛЕНИЯ}\label{chap1}


В настоящей главе приводится обзор основных результатов теории оптимального управления. Сначала обсуждаются формулировки задач, возникающих при оптимизации динамических систем управления. Затем приводятся основные результаты качественной теории --- принцип максимума Л.С. Понтрягина \cite{Pontryagin} и динамическое программирование Р. Беллмана.\cite{Bellman}

Наконец, рассматриваются наиболее часто применяемые на практике численные методы решения задач оптимального управления\cite{Diehl}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Задачи оптимального управления}\label{1sec:zop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Постановка любой конкретной задачи оптимального управления включает в себя 5 необходимых элементов: промежуток управления, математическую модель управляемого объекта, класс управлений и ограничений на них, ограничения на фазовую траекторию,
критерий качества.
Рассмотрим их подробнее.

1) Промежуток управления. Прежде всего задачи оптимального управления разделяются на непрерывные, рассматриваемые на некотором промежутке времени $T = [t_{0},t_{f}]$, и дискретные, в которых динамический процесс рассматривается в дискретные моменты времени $k = 0,1,...N$, где $N$ — натуральное число.

По продолжительности процесса различаются задачи с фиксированным и нефиксированным временем окончания процесса. Выделяются также задачи на бесконечном интервале.

В экономических приложениях динамические процессы, как правило, стационарны, поэтому процесс стартует в момент времени $t = 0$. В задачах с конечным промежутком времени момент окончания процесса $t = z$ называется горизонтом планирования.

2) Математическая модель. Динамика изучаемого процесса моделируется, как правило, дифференциальными

\begin{equation}\label{1v}\dot{x}(t) = f(x(t),u(t),t), \  t \in [t_0,t_f],\end{equation}
или разностными уравнениями

$$x(k + 1) = f(x(k),u(k),k), \ k = 0,1,...,$$
где $n$-вектор $x$ называется состоянием системы, $r$-вектор $u$ называется
управлением, функция $f : \R^{n} \times\ \R^{r} \times \R \rightarrow \R^{n} $ задана.

Число переменных состояния $n$ называется порядком системы управления, число $r$ — числом входов.

Далее будем рассматривать непрерывные системы вида (\ref{1v}).

3) Класс управлений и ограничения на них. Для непрерывного процесса управления указывается класс функций, из которого выбираются управления. Это могут быть: измеримые, дискретные, кусочно-непрерывные, гладкие, импульсные функции и т.д.

Кроме класса доступных управлений задается множество $U \subset \R^{r}$ — множество допустимых значений управления. Как правило, $U$ — компакт в $\R^{r}$.

Далее будем рассматривать управление в классе кусочно-непрерывных функций.

\begin{definition}Кусочно-непрерывная функция $u(\cdot) = (u(t), \ t \in [t_{0},t_{f}])$ называется доступным управлением, если $u(t) \in U, \  t \in [t_{0},t_{f}].$
\end{definition}

4) Ограничения на фазовую траекторию. Ограничения на переменные состояния могут накладываться:\begin{itemize}
\item в начальный момент времени $t_{0}$:
$$x(t_{0}) \in X_{0};$$
\item в конечный момент времени $t_{f}$, такие ограничения называются терминальными: $$x(t_{f}) \in X_{f};$$
\item в изолированные моменты $t_{i} \in [t_{0},t_{f}], \  i = \overline{1,m},$ из промежутка управления — промежуточные фазовые ограничения:
$$X(t_{i}) \in X_{i}, \ i = \overline{1,m};$$
\item на всем промежутке управления — фазовые ограничения:
$$x(t) \in X(t), \ t \in [t_{0},t_{f}],$$ где $X_{0}, X_{f}, X_{i}, i = \overline{1,m}, X(t), t \in [t_0,t_f],$ — заданные подмножества пространства состояний.
\end{itemize}
 Задача управления с $x(t_{f}) \in X_{f} $ называется:\begin{itemize}
  \item задачей со свободным правым концом траектории, если $X_{f} = \R^{n}$, \item задачей с закрепленным правым концом траектории, если $X_{f} = \{x_{f}\}$, \item задачей с подвижным правым концом траектории, если $X_{f}$ содержит более одной точки и не совпадает с $\R^{n}$.
\end{itemize}
 Аналогичная классификация имеет место для задач с ограничениями на левый конец траектории $x_{0} \in X_{0}$.

  Выделяют также смешанные ограничения, учитывающие связи между переменными состояния и переменными управления:
$$(u(t),x(t)) \in S \subseteq \R^r \times \R^n, \ t \in [t_{0},t_{f}[.$$ \begin{definition} Доступное управление $u(\cdot)$ называется допустимым (или, программой), если оно порождает траекторию $x(\cdot)=(x(t), \  t \in [t_0,t_f]$, удовлетворяющую всем заданным ограничениям задачи. \end{definition}

5) Критерий качества. Качество допустимого управления оценивается так называемым критерием качества

 Существуют четыре типа критерия качества:

i) критерий качества Майера (терминальный критерий)
$$J(u) = \varphi(x(t_{f})),$$

ii) критерий качества Лагранжа (интегральный критерий)
$$J(u) =\int^{t_{f}}_{ t_{0}}
f_{0}(x(t),u(t),t)dt,$$

iii) критерий качества Больца
$$J(u) = \varphi(x(t_{f})) +
\int^{t_{f}}_{ t_{0}}
f_0(x(t),u(t),t)dt,$$

iv) задачи быстродействия (являются задачами с нефиксированной продолжительностью процесса).
$$J(u) = t_{f} - t_{0} \rightarrow \min.$$
\begin{definition} Допустимое управление $u^{0}(\cdot)$ называется оптимальным управлением (оптимальной программой), если на нем критерий качества достигает экстремального значения (min или max):
$$J(u^0) = \extr J(u),$$
где минимум (максимум) берется по всем допустимым управлениям.
\end{definition}

В экономических приложениях наиболее часто встречающимися являются: критерий качества типа Больца --- для задач с конечным горизонтом планирования; критерий качества типа Лагранжа --- в задачах с бесконечным горизонтом. Нестационарность функции $f$ выражается наличием множителя дисконтирования $e^{-\rho t}.$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Принцип максимума и динамическое программирование}\label{1sec:pm} % xxx заменить на свою метку
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
В теории оптимального управления существует два фундаментальных результата: принцип максимума Л.С. Понтрягина\cite{Pontryagin} и динамическое программирование Р. Беллмана\cite{Bellman}. Приведем эти результаты на примере простейшей задачи оптимального управления.

 $$J(u) = \varphi(x(t_{f})) +
\int^{t_{f}}_{ t_{0}}
f_0(x(t),u(t),t)dt \rightarrow \min, $$
 \begin{equation}\label{tr2}\dot{x}(t)=f(x(t),u(t),t), \ x(t_0)=x_0,\end{equation}
$$u(t) \in U, \  t\in [t_0,t_f].$$

\subsection{Принцип максимума Понтрягина}

Принципом максимума называется основное необходимое условие оптимальности в задачах оптимального управления, связанное с максимизацией гамильтониана:

$$H(x,\psi, u, t) = \psi 'f(x, u, t) - f_0(x, u, t) = \sum^n_{j=1} \psi_j f_j(x, u, t) - f_0(x, u, t).$$ Здесь $\psi = \psi (t) \in \R^n $ --- сопряженная переменная.
\begin{theorem}Пусть $u^0(\cdot), x^0(\cdot)$ — оптимальное управление и траектория в задаче (\ref{tr2}) $\psi^0(\cdot)$ — соответствующее решение сопряженной системы
$$ \dot{\psi}^0(t)= -\frac{\partial H}{\partial x}(x^0(t),\psi^0(t),u^0(t),t),$$ с начальным условием
$$\psi^0(t_f) = - \frac{\partial\varphi}{\partial x}(x^0(t_f)). $$
Тогда для любого $t \in [t_0,t_f]$, управление $u^0(t)$ удовлетворяет условию:
$$H(x^0(t),\psi^0(t),u^0(t),t) = \max_{v\in U}
H(x^0(t),\psi^0(t),v,t), \ t \in [t_0,t_f].$$
\end{theorem}

Для того чтобы решить задачу с помощью принципа максимума обычно поступают следующим образом. Функцию $H(x, \psi ,u,t)$ рассматривают как функцию $r$  переменных $u = (u_1,...,u_r).$ Далее проводят поточечную оптимизацию для каждого фиксированного набора $(x, \psi ,t)$
\begin{equation}\label{krz}U(x, \psi ,t) = \arg \max_{v \in U} H(x, \psi , v, t).\end{equation}
Если исходная задача (\ref{tr2}) имеет решение, функция (\ref{krz}) определена на непустом множестве значений $(x, \psi , t).$

Пусть  $u$ в виде (\ref{krz}) найдена, тогда можно рассмотреть следующую систему с граничными условиями:
$$ \dot{x} =\frac{\partial{H}}{\partial{\psi}}(x, \psi , u(x, \psi , t), t) = f(x, \psi , u(x, \psi , t), t), x(t_0) = x_0,$$
$$ \dot{\psi } = - \frac{\partial{H}}{\partial{x}}(x, \psi , u(x, \psi , t), t), \  \psi (t_f) = -\frac{\partial{\varphi(x(t_f))}}{\partial{x}}.$$
Таким образом получена специальная краевая задача, которая называется краевой задачей принципа максимума.

Можно ожидать, что имеются лишь отдельные изолированные пары функций $x(\cdot), \psi (\cdot),$ удовлетворяющие краевой задаче принципа максимума. Подставив одну такую пару в (\ref{krz}), получим:$$u(t) = u(x(t), \psi (t),t), \  t \in [t_0, t_f],$$
которая удовлетворяет принципу максимума и, значит, может претендовать на роль оптимального управления, а функция $x(t) = x(t\mid t_0,x_0,u(\cdot)), \  t\in [t_0, t_f],$ --- на роль оптимальной траектории в задаче.

Отметим, что принцип максимума в задаче (\ref{tr2}) является лишь необходимым условием оптимальности, поэтому построенное управление может не быть оптимальным. Построенная функция называется экстремалью Понтрягина.
\subsection{Динамическое программирование}

Рассмотрим задачу (\ref{tr2}) и предположим, что она имеет решение. Следуя динамическому программированию\cite{Bellman}, погрузим задачу (\ref{tr2}) в семейство задач
$$ J_{\tau ,z}(u) = \varphi (x(t_f)) + \int^{t_{f}}_{\tau }
f_0(x(t),u(t),t)dt \rightarrow \min, $$
 \begin{equation}\label{dp1}\dot{x}(t)=f(x,u), \ x(\tau )=z, \ x(t_f) \in X,\end{equation}
$$u(t) \in , \ t\in T = [\tau ,t_f],$$
зависящих от скаляра $\tau \in T$ и $n$-вектора $z.$

Пару $(\tau , z)$ назовем позицией в задаче (\ref{tr2}). Обозначим через $$B(\tau ,z) = \min_{u(t|\tau ,z)} J_{\tau ,z} (u)$$
минимальное значение критерия качества в задаче (\ref{dp1}) для позиции $(\tau , z)$. Если для позиции  $(\tau , z)$ задача (\ref{dp1}) не имеет решения, то положим $B(\tau ,z) =  +\infty$. Пусть $$X_{\tau } = \{z \in \R^n : B(\tau ,z) < +\infty \}.$$
Функцию\begin{equation}\label{fb} B(\tau ,z), \ z \in X_{\tau}, \ \tau \in T,\end{equation} называют функцией Беллмана.

Уравнение в частных производных, которому удовлетворяет функция (\ref{fb}), называют уравнением Беллмана
\begin{equation}\label{ub} -\frac{\partial B(\tau,z)}{\partial\tau} = \min_{v \in U}\left\{ \frac{\partial B'(\tau,z)}{\partial z}f(z,v) + f_0(z,v)\right\}, \ z \in X_\tau, \ \tau \in T.\end{equation}
Выделяя из семейства (\ref{dp1}) задачу с $\tau = t_f$, находим граничное условие для уравнения Беллмана \cite{GabasovOLS}:
\begin{equation}\label{gusl}B(t_f,z)=\begin{cases}
\varphi(z), \ \ z \in X, \\
+\infty , \ \ z \not\in X.
\end{cases}\end{equation}

Схема применения динамического программирования состоит в следующем:
\begin{itemize}
  \item Для задачи составляется уравнение Беллмана.
  \item По решению уравнения строится позиционное решение.
 \end{itemize}
Эффективно строить решение уравнения Беллмана удается в редких случаях. В общем случае необходимо привлекать численные методы.
\section{Классификация численных методов решения. Прямые методы}
Численные методы решения задач оптимального управления можно разделить на три категории:
\begin{itemize}
\item динамическое программирование;
\item непрямые методы, основанные на принципе максимума;
\item прямые методы.
\end{itemize}


Основная трудность динамического программирования состоит в табулировании функций многих переменных, что приводит к так называемому "проклятию размерности".

Проблема непрямых методов в том, что не существует универсальных способов решения краевых задач для обыкновенных (нелинейных) дифференциальных уравнений.

Прямые методы основаны на сведении задачи оптимального управления к задаче нелинейного программирования посредством параметризации функций управления.

Последняя группа методов является самой распространенной в практических приложениях, поэтому далее описываются два представителя класса прямых методов: Direct Single Shooting(DSS) и Direct Multiple Shooting(DMS).
\subsection{Direct Single Shooting}

Опишем основные принципы метода DSS на примере задачи управления нелинейной стационарной системой с критерием качества типа Больца, со смешанными и терминальными ограничениями:
 $$J(x,u) = \int^{t_f}_0 f_0(x(t),u(t))dt + \varphi(x(t_{f})) \rightarrow \min_{x,u},$$
 $$x(0)=x_0,$$
\begin{equation}\label{zzz}\dot{x}=f(x(t),u(t)), \ t \in [0, t_f],\end{equation}
 $$h(x(t),u(t)) \leq 0, \ t \in [0, t_f],$$
 $$r(x(t_f)) \leq 0.$$

Обозначим через $q \in \R^{rN}$ вектор параметров управления; cамо управление будем обозначать $u(t,q), \ t \in [t_0, t_f],$ подчеркивая его зависимость от параметра $q \in \R^{rN}.$ В большинстве случаев параметризация является кусочно-постоянной: выбирается фиксированная сетка $0 = t_0 < t_1 <... <t_N = t_f$ и $N$ параметров $q_i \in \R^{r}, \ i = \overline{0, N-1}$; тогда
$$u(t,q) = q_i, \ t \in [t_i, t_{i+1}[, \ i = \overline{0, N-1}.$$

Direct Single Shooting является последовательным методом, это означает, что переменная $x$ исключается из задачи (\ref{zzz}). При выбранном векторе $q$ состояние $x(t), t \in [0, t_f]$, выражается как
$$x(t_i, q) = x(t_i| t_{i-1}, x(t_{i-1},q),q_{i-1}), \ i = \overline{0, N-1},$$
$$x(t_0,q) = x_0.$$

Ограничения на траекторию при выбранной параметризации, как правило, проверяют в узлах выбранной сети, т.е. требуют выполнения:
$$ h(x(t_i,q),u(t_i,q)) \leq 0, \ i = \overline{0, N-1}.$$
В результате получим задачу конечномерной оптимизации:

$$J(q) = \int^{t_f}_0 f_0(x(t,q),u(t,q))dt + \varphi(x(t_{f},q)) \rightarrow \min_q,$$
\begin{equation}\label{DSS}
h(x(t_i,q),u(t_i,q)) \leq 0, \  i = \overline{0, N-1},\end{equation}
$$r(x(t_f,q) \leq 0, \ q \in \R^{rN}.$$
Данный метод позволяет обойти проблему "проклятия размерности".
\subsection{Direct Multiple Shooting}

Опишем основные принципы метода DMS на примере задачи управления нелинейной стационарной системой с критерием качества типа Больца, со смешанными и терминальными ограничениями (\ref{zzz}). Так же как и в DSS введем $q \in \R^{rN}$, получим:
$$u(t,q) = q_i, t \in [t_i, t_{i+1}[, \ i = \overline{0, N-1}.$$

Затем решаем ОДУ на каждом интервале  $t \in [t_i, t_{i+1}[, \ i = \overline{0, N-1}$, начиная с искусственных начальных значений $s_i$:
$$
\dot{x}_i (t, s_i, q_i) = f (x_i (t| s_i, q_i), q_i), \ t \in [t_i, t_{i + 1}[,$$ $$ x_i(t_i| s_i, q_i) = s_i.$$

Таким образом, получим отрезки траектории $x_i (t| s_i, q_i).$

Аналогично, численно вычисляем интегралы

$$F_i (s_i, q_i) = \int^{t_i+1}_{t_i} f_0(x_i(t_i,s_i,q_i),q_i)dt.$$

Выберем сетку, в которой проверяем ограничения неравенства; здесь подчеркиваем зависимость от параметра $q \in \R^{rN}.$ В большинстве случаев параметризация является кусочно-постоянной: выбирается фиксированная сетка.
Получим задачу:
$$J(q) = \sum F_i (s_i, q_i) + \varphi(s_{N}) \rightarrow \min_{q,s},$$
$$x_0 - s_0 = 0,$$
$$x_i (t_{i + 1}| s_i, q_i) - s_{i + 1} = 0, \ i = \overline{0,N-1},$$
$$h (s_i, q_i) \leq 0, \ i =\overline{0, N},$$
$$r (s_N) \leq 0.$$

Обратим внимание, что выбрав $f_i (s_i, q_i) = x_i (t_{i + 1}| s_i, q_i)$ условия непрерывности могут быть интерпретированы как динамическая система с дискретным временем
$$s_{i + 1} = f_i (s_i, q_i),$$и вышеупомянутая задача оптимального управления имеет точно такую же структуру, что и задача оптимального управления с дискретным временем.

\bigskip
Отличие Direct Single Shooting от Direct Multiple Shooting состоит в том, что в первом случае траектория вычисляется последовательно, во втором - одновременно. В главе 4 будет представлена программная реализация прямых методов на примере конкретной задачи оптимального управления. 